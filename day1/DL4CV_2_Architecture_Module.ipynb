{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_introCV_Experis2020/blob/main/DL4CV_2_Architecture_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxbHHmkf_siR"
   },
   "source": [
    "![](images/intro.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sELgQ5b_siS"
   },
   "source": [
    "# **Welcome!**\n",
    "\n",
    "## Introduction to Machine Learning for Computer Vision\n",
    "\n",
    "\n",
    "\n",
    "## **Lecturer :** Matteo Alberti\n",
    "\n",
    "![](data:image/jpeg;base64,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)\n",
    "\n",
    "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wp5gD9sU_siT"
   },
   "source": [
    "# Summary\n",
    "\n",
    "\n",
    "- <font color=C24024>**Best Practices & Basic Architecture** </font> : [LeNet]\n",
    "\n",
    "- <font color=CA4A2F>**Train a Convolutional Networks with Keras** </font> : \n",
    "\n",
    "    - <font color=E35F2A>**Work with Model** </font>\n",
    "\n",
    "    - <font color=EF8932>**Work with data** </font> : [Visualize inside CNN]\n",
    "\n",
    "- <font color=F4C52D>**Exercises & Tips** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKw6CAGn_siU"
   },
   "source": [
    "#### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "5okCFTqa_siV",
    "outputId": "f5c5474e-844e-44d1-c127-9f3bc88fff41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version :  2.3.0\n",
      "Python Version :  3.6.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lO31w7ue_sib"
   },
   "source": [
    "### Load Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "lfm5Aw6G_sib",
    "outputId": "9b3294c0-61cf-4429-c5e8-2bef05d14487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n",
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV_0hnVeP3QT"
   },
   "source": [
    "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/07/Depiction-of-CNN-Model-for-Accelerompter-Data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDVgTi3__sis"
   },
   "source": [
    "##### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3pBq_Mz_sit"
   },
   "outputs": [],
   "source": [
    "#The range for each individual colour is 0-255\n",
    "x_train = x_train.astype('float32')/255 \n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMTbJ5JS_six"
   },
   "source": [
    "### Define HyperParameters & CNN Architecture\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pgGrSQss_siy",
    "outputId": "4611b80f-8d8d-4dd4-c219-2fa043421a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, channel=3, classes=10, dropout=0.5, early_stop=3, epochs=20, height=32, iter=100, layers_res=152, lr=0.001, stack_n=25, train=False, weight_decay=0.0001, width=32)\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "import sys;import argparse; sys.argv=['']; del sys\n",
    "parser = argparse.ArgumentParser(description=\"CNN\")\n",
    "parser.add_argument('--epochs', default=20, type=int)\n",
    "parser.add_argument('--iter', default=100, type=int)\n",
    "parser.add_argument('--batch_size', default=128, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float)\n",
    "\n",
    "#For VGG\n",
    "parser.add_argument('--weight_decay', default=0.0001, type=float)\n",
    "parser.add_argument('--dropout', default=0.5, type=float)\n",
    "\n",
    "\n",
    "parser.add_argument('--height', default=32, type=int)\n",
    "parser.add_argument('--width', default=32, type=int)\n",
    "parser.add_argument('--channel', default=3, type=int)\n",
    "parser.add_argument('--classes', default=10, type=int)\n",
    "\n",
    "#FOR RESNET\n",
    "parser.add_argument('--stack_n', type=int, default=25, metavar='NUMBER',\n",
    "                help='stack number n, total layers = 6 * n + 2 (default: 5)')\n",
    "\n",
    "parser.add_argument('--train', default=False)\n",
    "args = parser.parse_args()\n",
    "\n",
    "layers_res = 6 * args.stack_n + 2\n",
    "parser.add_argument('--layers_res', default=layers_res)\n",
    "\n",
    "#Extras\n",
    "parser.add_argument('--early_stop', default=3)\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is so useful?**\n",
    "\n",
    "\n",
    "- \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDNeEziX_si4"
   },
   "source": [
    "### Baseline Convolutional architecture in Keras : [LeNet]\n",
    "\n",
    "\n",
    "![](https://irenelizihui.files.wordpress.com/2016/03/tf43.png)\n",
    "\n",
    "***Commented VERSION***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFgEZmMN_si5"
   },
   "outputs": [],
   "source": [
    "def build_Lenet(height,width,channel,classes):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    #Features Extractor\n",
    "    model.add(tf.keras.layers.Conv2D(6, (5, 5), \n",
    "                     padding='valid', \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer='he_normal', #https://keras.io/initializers/#randomnormal\n",
    "                     input_shape=(height,width,channel)))\n",
    "    \n",
    "    \"\"\"    \n",
    "    **Valid** -> without padding\n",
    "    \n",
    "    inputs:         1  2  3  4  5  6  7  8  9  10 11 (12 13)\n",
    "                      |________________|                dropped\n",
    "                                     |_________________|\n",
    "                                     \n",
    "   **Same** -> with zero padding\n",
    "   \n",
    "                pad|                                      |pad\n",
    "   inputs:      0 |1  2  3  4  5  6  7  8  9  10 11 12 13|0  0\n",
    "               |________________|\n",
    "                              |_________________|\n",
    "                                             |________________|\n",
    "                                     \n",
    "    \"\"\"\n",
    "    \n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Conv2D(16, (5, 5), padding='valid', \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer='he_normal'))\n",
    "    \n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten()) # unrolls the values beginning at the last dimension\n",
    "    \n",
    "    \"\"\"\n",
    "    We need to convert the output of the convolutional part of the CNN \n",
    "    into a 1D feature vector during the classification part\n",
    "    \n",
    "    It gets the output of the convolutional layers, \n",
    "    flattens all its structure to create a single long \n",
    "    feature vector to be used by the dense layer \n",
    "    for the final classification\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Classification\n",
    "    model.add(tf.keras.layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(tf.keras.layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(tf.keras.layers.Dense(classes, activation = 'softmax', \n",
    "                    kernel_initializer='he_normal'))\n",
    "    \n",
    "    #Compile & Optimizers\n",
    "    sgd = tf.keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8mgBOOjG79k"
   },
   "source": [
    "***Summary***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U1gic96FfJU"
   },
   "outputs": [],
   "source": [
    "def build_Lenet(height,width,channel,classes):\n",
    "    \n",
    "    return tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(6, (5, 5), \n",
    "                     padding='valid', \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer='he_normal',\n",
    "                     input_shape=(height,width,channel)),\n",
    "\n",
    "     \n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (5, 5), padding='valid', \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer='he_normal'),\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(classes, activation = 'softmax', \n",
    "                    kernel_initializer='he_normal')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arODtwrx_si9"
   },
   "source": [
    "#### Extra Notes:\n",
    "\n",
    "    - Why do we need activation function on convolutions?\n",
    "\n",
    "The purpose of activation functions is mainly to add non-linearity to the network, which otherwise would be only a linear model. A convolutional layer by itself is linear exactly like the fully connected layer.\n",
    "\n",
    "In fact if you visualize each pixel of the input and output images as a node, then you would obtain a fully connected layer with a lot less edges. Or, in other words, the input values get multiplied by coefficients. Following a complex logic, but nothing more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "QJnm4WnP_si9",
    "outputId": "76a6824e-dd7e-4a6b-ed9f-fdc6b104b2f1"
   },
   "outputs": [],
   "source": [
    "# build network\n",
    "lenet_base = build_Lenet(height=args.height, \n",
    "                         width=args.width, \n",
    "                         channel=args.channel, \n",
    "                         classes=args.classes)\n",
    "\n",
    "lenet_base.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "lenet_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG5qVmbf_sjD"
   },
   "source": [
    "### We can use also the following code to provide a beautiful representation of our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "id": "2DVaGWla_sjG",
    "outputId": "281ae6d3-6ad9-480b-dce1-e8e5b43f1aac"
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(lenet_base, show_shapes=True, \n",
    "             show_layer_names=True, \n",
    "             rankdir='TB', dpi=65 ).create(prog='dot', \n",
    "                                  format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OdcpVCU_sjM"
   },
   "source": [
    "### What we need for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "w5Dc85jZ_sjN",
    "outputId": "e8284ca2-d094-44ba-92bc-536d66f2cedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpzMsoHG_sjQ"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wEScKHIz_sjQ",
    "outputId": "387d0052-ef8a-4df3-9e70-351f6fc9cb4f"
   },
   "outputs": [],
   "source": [
    "# start train\n",
    "history_lenet = lenet_base.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=50,\n",
    "          validation_split=0.2, \n",
    "          callbacks=[tensorboard_callback], verbose=1)\n",
    "\n",
    "# save model\n",
    "#lenet_base.save('./pretrained_model/lenet25.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3Iu3KLn_sjV"
   },
   "source": [
    "##### Save and Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lo7EjMFJ_sjW"
   },
   "outputs": [],
   "source": [
    "lenet_base.save_weights('./pretrained_model/lenet25.h5')\n",
    "lenet_base.load_weights('./pretrained_model/lenet25.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4rs0XcZ_sjZ"
   },
   "source": [
    "### Evaluate Prediction & plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFPJPhJD_sja"
   },
   "outputs": [],
   "source": [
    "score = lenet_base.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PsZ8fggv_sjd",
    "outputId": "7f68dfd9-09c5-4088-900b-1b978d556358"
   },
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "_IukERBn_sjg",
    "outputId": "527739b2-117f-4b33-a5f0-127cf62b5f7d"
   },
   "outputs": [],
   "source": [
    "print(score[0], ' : loss')\n",
    "print(score[1]*100, '% : acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiiBF39OdzqH"
   },
   "source": [
    "### Any other idea??\n",
    "\n",
    "- try to fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK5gmRFdd2PY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred1 = lenet_base.predict(x_test)\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl1tAh3iKRqa"
   },
   "source": [
    "## Graphical Evaluation\n",
    "\n",
    "#### First Way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NKkbYsnIKZfG"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppynwLHwLRUA"
   },
   "source": [
    "```\n",
    "A brief overview of the dashboards shown (tabs in top navigation bar):\n",
    "```\n",
    "- The **Scalars** dashboard shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values.\n",
    "\n",
    "- The **Graphs** dashboard helps you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly.\n",
    "\n",
    "- The **Distributions** and Histograms dashboards show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way.\n",
    "\n",
    "\n",
    "Additional TensorBoard plugins are automatically enabled when you log other types of data. For example, the Keras TensorBoard callback lets you log images and embeddings as well. You can see what other plugins are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXHvKtUcKbwE"
   },
   "source": [
    "#### Second Way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4qY4gxi_sjj"
   },
   "outputs": [],
   "source": [
    "def SHOWPREDICTION(orig, model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    try:\n",
    "        img_class = model.predict_classes(orig[:5])\n",
    "    except AttributeError:\n",
    "        y_pred1 = model.predict(orig[:5])\n",
    "        img_class = np.argmax(y_pred1,axis=1)\n",
    "        \n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for i in range(5):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(orig[i].reshape(32, 32, 3))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        label_name = load_label_names()\n",
    "        plt.title(label_name[i])\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "  \n",
    "\n",
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "k6tm5JAh_sjm",
    "outputId": "ea34f1e0-9eb8-4c36-ecd1-e90838203059"
   },
   "outputs": [],
   "source": [
    "labelNames = np.array(load_label_names())\n",
    "\n",
    "# How CNN Classifies an Image?\n",
    "img_idx = 122\n",
    "plt.imshow(x_test[img_idx],aspect='auto')\n",
    "print('Actual label:', labelNames[y_test[img_idx]])\n",
    "# Preper image to predict\n",
    "test_image =np.expand_dims(x_test[img_idx], axis=0)\n",
    "print('Input image shape:',test_image.shape)\n",
    "print('Predict Label:',labelNames[lenet_base.predict_classes(test_image,batch_size=1)[0]])\n",
    "print('\\nPredict Probability:\\n', lenet_base.predict_proba(test_image,batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "ldYQMhzO_sjp",
    "outputId": "1791ea6c-daf6-4c03-8012-9fc8e871ec49"
   },
   "outputs": [],
   "source": [
    "SHOWPREDICTION(x_test, model=lenet_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5urKaEKB_sjs"
   },
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouRz8MHd_sjv"
   },
   "outputs": [],
   "source": [
    "# ---> TRAINED WITH 50 epochs <----\n",
    "plot_model_history(history_lenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xflSiRT5_sjy"
   },
   "source": [
    "## How appears our training history?\n",
    "\n",
    "![](https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB8z1I8Y_sjz"
   },
   "source": [
    "    First of all.. train a lot of time..\n",
    "    \n",
    "    But, this isn't enought!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHL75TbV_sj0"
   },
   "outputs": [],
   "source": [
    "# ---> TRAINED WITH 50 epochs <----\n",
    "plot_model_history(history_lenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boj2pwc6_sj3"
   },
   "source": [
    "![](images/lenet_50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pco3pPh-_sj3"
   },
   "source": [
    "##### But adding epochs doesn't resolve everything.. how can we improve performances?\n",
    "    \n",
    "    Two possible ways:\n",
    "    - work with model (An example : Dropout)\n",
    "    - work with data  (An example : Data Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDj8htJJ_sj_"
   },
   "source": [
    "## Improve Model performances\n",
    "\n",
    "![](https://d3i71xaburhd42.cloudfront.net/fd66fae4891a7993a66ca98fcdc8ce2207bee8b8/4-Figure2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nf8b112z_skA"
   },
   "source": [
    "#### Exercise :\n",
    "\n",
    "- play with LeNet\n",
    "    - Change hyperparameters, optimizers, receipt fiels and evaluate the performance.\n",
    "    - *Keep your best model. We'll use it later :)*\n",
    "    \n",
    "Sometime you will have to debug.. remember : debugging neural networks isn't like debugging \"standard\" code. Most of the time *the solution is hidden behind theory*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCIS0Uhn_skA"
   },
   "outputs": [],
   "source": [
    "def build_Lenet_test(height,width,channel,dropout,classes):\n",
    "    \n",
    "    return tf.keras.models.Sequential([])\n",
    "    \n",
    "    \"\"\"\n",
    "    --> Keep fixed other hyperparameters. \n",
    "        You need to be able to compare this architectures\n",
    "        (but later this will not properly manteined)\n",
    "    \n",
    "    \n",
    "    ----> try not to look above <----\n",
    "    \n",
    "    1) try different epochs / batch size - are there any kind of limits?\n",
    "    2) try different optimizers - evaluate how fast converge\n",
    "    \n",
    "    ... \n",
    "    \n",
    "    3) try to change the receipt field (pay attention!)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# build network\n",
    "lenet_test = build_Lenet_test(height=args.height, width=args.width, \n",
    "                          channel=args.channel,\n",
    "                          classes=args.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CBOFozy_skD"
   },
   "source": [
    "### [Work with Model] Define Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv5Sg-H3_skD"
   },
   "source": [
    "![](https://miro.medium.com/max/1044/1*iWQzxhVlvadk6VAJjsgXgg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Lxk8i_U_skE"
   },
   "source": [
    "Dropout is a regularization technique for deep neural\n",
    "networks, where it follows the Bernoulli distribution to decide\n",
    "which node to keep or drop.\n",
    "- Different DNNs can be obtained by using dropout for every layer\n",
    "during training as well as testing, and it has been shown that they\n",
    "are mathematically equivalent to samples from a BDNNs.\n",
    "\n",
    "**Pros :**\n",
    "‒ It is easy to turn an existing deep net into a Bayesian one. it is faster than\n",
    "other techniques, and does not require an inference framework.\n",
    "\n",
    "**Cons :**\n",
    "‒ Sampling at test time might be too expensive for computationally‐\n",
    "demanding (eg real time) applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F23hgVPV_skF"
   },
   "source": [
    "![](images/dropout2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRu37RNb_skG"
   },
   "source": [
    "#### Develop New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pG4IWkT0_skG"
   },
   "outputs": [],
   "source": [
    "# Choose your best architecture and retrain with a Dropout!\n",
    "\n",
    "def build_Lenet_dp(height,width,channel,dropout,classes):\n",
    "    \n",
    "    return tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.Conv2D(6, (5, 5), \n",
    "                     padding='valid', \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer='he_normal',\n",
    "                     input_shape=(height,width,channel)),\n",
    "\n",
    "    # DROPOUT \n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (5, 5), padding='valid', \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer='he_normal'),\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(classes, activation = 'softmax', \n",
    "                    kernel_initializer='he_normal')])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# build network\n",
    "lenet_dp = build_Lenet_dp(height=args.height, width=args.width, \n",
    "                          channel=args.channel, dropout=args.dropout,\n",
    "                          classes=args.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeEIQbUy_skJ"
   },
   "outputs": [],
   "source": [
    "# COMPILE\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "\n",
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDDwcE1LR1Nb"
   },
   "source": [
    "*Any improvments?*\n",
    "\n",
    "- accuracy :\n",
    "- loss :\n",
    "- time to execution :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tU4uqdY_skW"
   },
   "source": [
    "### [Work with Data] Develop data augmentation\n",
    "\n",
    "<div>\n",
    "<img src=\"https://paperswithcode.com/media/tasks/rsz_screenshot_2019-11-29_at_122132_S80u6gv.png\" width=\"500\"/>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/732/1*WboGzP5KP12n0hdPRN0JsQ.png\" width=\"500\"/>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auxB550o_skX"
   },
   "source": [
    "Pay attention with Data Augmentation:\n",
    "\n",
    "- Need some extra time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qELjuxyVA5M"
   },
   "source": [
    "### Set-up Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ncSOC13G_skY"
   },
   "outputs": [],
   "source": [
    "# set up image augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    "    #zoom_range=0.3\n",
    "    )\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "id": "6U9OtDuJ_skb",
    "outputId": "192483e0-0b51-4113-e9dc-9b768414bb27"
   },
   "outputs": [],
   "source": [
    "# see example augmentation images\n",
    "plt.figure(figsize=(6, 6))\n",
    "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        plt.imshow(X_batch[i].astype(np.uint8))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2RQatkO_ske"
   },
   "source": [
    "## Retrain our best model with [DA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUGOTcEY_skf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start train \n",
    "history_lenet_dp_da = lenet_base.fit_generator(datagen.flow(x_train, y_train,batch_size=args.batch_size),\n",
    "                    steps_per_epoch=args.iter,\n",
    "                    epochs=args.epochs*2,\n",
    "                    callbacks=cbks,\n",
    "                    validation_data=(x_test, y_test), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cz6BPRzX_skh"
   },
   "outputs": [],
   "source": [
    "labelNames = np.array(load_label_names())\n",
    "\n",
    "# How CNN Classifies an Image?\n",
    "img_idx = 122\n",
    "plt.imshow(x_test[img_idx],aspect='auto')\n",
    "print('Actual label:', labelNames[y_test[img_idx]])\n",
    "# Preper image to predict\n",
    "test_image =np.expand_dims(x_test[img_idx], axis=0)\n",
    "print('Input image shape:',test_image.shape)\n",
    "print('Predict Label:',labelNames[lenet_dp.predict_classes(test_image,batch_size=1)[0]])\n",
    "print('\\nPredict Probability:\\n', lenet_dp.predict_proba(test_image,batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enO5-hAV_skl"
   },
   "outputs": [],
   "source": [
    "plot_model_history(history_lenet_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "why-bfk7WQ99"
   },
   "source": [
    "## *Try with lenet + dropout + data augmentation!!*\n",
    "\n",
    "- Accuracy :\n",
    "- Loss :\n",
    "- Time :\n",
    "\n",
    "- Plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etYnofGmXTAN"
   },
   "source": [
    "## Wanna see an interactive session during training? \n",
    "\n",
    "*Check this link!*\n",
    "\n",
    "https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nf8b112z_skA",
    "9CBOFozy_skD",
    "bRu37RNb_skG",
    "5tU4uqdY_skW"
   ],
   "include_colab_link": true,
   "name": "DL4CV - 2 - Architecture Module.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.545px",
    "left": "1390.45px",
    "right": "20px",
    "top": "37px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
