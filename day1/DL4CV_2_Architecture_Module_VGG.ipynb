{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_introCV_Experis2020/blob/main/DL4CV_2_1_Architecture_Modeule_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeUV6Jp4aJf_"
   },
   "source": [
    "# **Welcome!**\n",
    "\n",
    "# Introduction to Machine Learning for Computer Vision\n",
    "\n",
    "#### Deeper Architectures:  Visual Geometry Group Network [VGG]\n",
    "\n",
    "\n",
    "## **Lecturer :** Matteo Alberti\n",
    "\n",
    "![](data:image/jpeg;base64,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)\n",
    "\n",
    "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTx_Et6haD0Q"
   },
   "source": [
    "# Summary\n",
    "\n",
    "- <font color=C24024>**Deep Convolutional Neural Networks** </font> : [VGG Net]\n",
    "\n",
    "- <font color=CA4A2F>**Hands-On** </font> : from Paper to Code\n",
    "\n",
    "- <font color=F4C52D>**Exercises & Tips** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BwjPMCmaD0W"
   },
   "source": [
    "Paper : [VERY DEEP CONVOLUTIONAL NETWORKS\n",
    "FOR LARGE-SCALE IMAGE RECOGNITION, Karen Simonyan & Andrew Zisserman+](https://github.com/matteoalberti/Lectures_introCV_Experis2020/blob/main/docs/VGG.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7IfR1F_SaD0Y"
   },
   "outputs": [],
   "source": [
    "#TF Imports\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the architecture : Read the paper and compile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Yd9apjNKaD0i"
   },
   "outputs": [],
   "source": [
    "input_shape = (###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SR37xofmaD0r"
   },
   "outputs": [],
   "source": [
    "#Instantiate an empty model --> Sequential or Functional?\n",
    "\n",
    "def build_VGG(input_shape, n_classes):\n",
    "    \n",
    "    return tf.keras.models.Sequential([\n",
    "        \n",
    "        ###\n",
    "        \n",
    "        \n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963
    },
    "id": "fDiBhsTmuvOy",
    "outputId": "ed7999ea-710e-4835-acd9-d2a3f0d2b7a1"
   },
   "outputs": [],
   "source": [
    "#Define\n",
    "VGG_model = build_VGG(input_shape=input_shape, n_classes=1000)\n",
    "\n",
    "#Compile architecture\n",
    "VGG_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Show\n",
    "VGG_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1njOTrHNvZvS"
   },
   "source": [
    "# Adapt an architecture to our Domain!\n",
    "\n",
    "*Test on Cifar10! Load data from tf.keras.datasets (Just for this time ;))*\n",
    "\n",
    "Or you can try with local data loading and solve step-by-step each problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-hdnCx8aD0x"
   },
   "source": [
    "## Test on Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "rBSLaJ3iaD0y",
    "outputId": "a34d7c46-38a4-4587-cb3f-209aadc04185"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The range for each individual colour is 0-255\n",
    "\n",
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q-BZS-FjaD02"
   },
   "outputs": [],
   "source": [
    "# NEW SHAPE!\n",
    "input_shape = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 963
    },
    "id": "Nxv0nRzSaD06",
    "outputId": "f7bd828f-2676-4098-8bca-a65d24903dee"
   },
   "outputs": [],
   "source": [
    "# Define Model\n",
    "VGG_model = build_VGG()\n",
    "\n",
    "#Compile architecture\n",
    "VGG_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Show\n",
    "VGG_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fytTmM-rxUig"
   },
   "outputs": [],
   "source": [
    "# define callbacks -----> REMEMBER TO SET A DIFFERENT FOLDER EACH TIME\n",
    "\n",
    "%load_ext tensorboard\n",
    "log_dir = \"logs/fit/VGG/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5g4N1aGeaD1M"
   },
   "outputs": [],
   "source": [
    "# TRAIN NETWORK!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T15:45:26.626800Z",
     "start_time": "2020-10-07T15:45:26.615156Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "sg70yJEoxsK0",
    "outputId": "ed637468-0fbc-47c3-903c-2f080636659f"
   },
   "outputs": [],
   "source": [
    "# Evaluate ACC and LOSS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do you wanna ad hoc plot? Build it with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E0PQ1f67aD1P"
   },
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MxxCw8p-aD1T"
   },
   "outputs": [],
   "source": [
    "plot_model_history(history_VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "KlXX_o0uaD1W",
    "outputId": "415733b2-e13b-4a0f-aae6-d32e5842d278"
   },
   "outputs": [],
   "source": [
    "labelNames = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "# How CNN Classifies an Image?\n",
    "img_idx = 3\n",
    "plt.imshow(x_test[img_idx],aspect='auto')\n",
    "print('Actual label:', labelNames[x_test[img_idx]])\n",
    "# Preper image to predict\n",
    "test_image =np.expand_dims(x_test[img_idx], axis=0)\n",
    "print('Input image shape:',test_image.shape)\n",
    "print('Predict Label:',labelNames[VGG_model.predict_classes(test_image,batch_size=1)[0]])\n",
    "print('\\nPredict Probability:\\n', VGG_model.predict(test_image,batch_size=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8MLoazsaD1f"
   },
   "source": [
    "## Notes :\n",
    "\n",
    "- The padding is chosen as 1 pixel so the spatial resolution is preserved through the convolutional layers. Thus, the spatial resolution will only change at the pooling layers\n",
    "- The pooling layer does not learn anything\n",
    "- fully-connected layers : Activation size previous layer * Activation size actual layer + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNILEFY-aD1k"
   },
   "source": [
    "### Do you want to check other VGG Net configurations easly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3F2Q_9SaD1p"
   },
   "outputs": [],
   "source": [
    "vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "    pooling=None, classes=1000, classifier_activation='softmax')\n",
    "\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gMQGz2NwwC0"
   },
   "source": [
    "### Parameters :\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "DL4CV - 2.1 - Architecture Modeule VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
